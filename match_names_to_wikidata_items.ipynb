{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match AVH collectors to Wikidata items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Wikidata data set\n",
    "\n",
    "[Jupyter Notebook for creating the Wikidata data set](./create_wikidata_dataset.ipynb)\n",
    "\n",
    "Out of the Wikidata items data set we create a data frame with unique canonical name strings and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (9,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      canonical_string  item\n",
      "                       count\n",
      "95344        Ǒwaki, K.     1\n",
      "95345   Șerbanescu, I.     1\n",
      "95346     Șuster, P.M.     1\n",
      "95347          Șık, L.     1\n",
      "95348         Țopa, E.     1\n"
     ]
    }
   ],
   "source": [
    "wikidata = pd.read_csv('data/wikidata_persons.csv')\n",
    "wikidata = wikidata.iloc[:, 1:]\n",
    "\n",
    "wd_test = wikidata.groupby('canonical_string').agg({'item': ['count']}).reset_index()\n",
    "\n",
    "print(wd_test.tail())\n",
    "\n",
    "# colls = list(wikidata.columns)\n",
    "# wikidata = wikidata[[colls[-1]] + colls[0:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load AVH collectors data set\n",
    "\n",
    "[Jupyter Notebook for creating the AVH collectors data set](./create_avh_collectors_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               label                     i18nCode  count  \\\n",
      "0  Beauglehole, A.C.  collector.Beauglehole, A.C.  90942   \n",
      "1      Forster, P.I.      collector.Forster, P.I.  64649   \n",
      "2         Hyland, B.         collector.Hyland, B.  57265   \n",
      "3           Latz, P.           collector.Latz, P.  51230   \n",
      "4      Streimann, H.      collector.Streimann, H.  45346   \n",
      "\n",
      "                              fq  start_date  end_date  activity_span  \n",
      "0  collector:\"Beauglehole, A.C.\"      1865.0    2005.0          140.0  \n",
      "1      collector:\"Forster, P.I.\"      1955.0    2018.0           63.0  \n",
      "2         collector:\"Hyland, B.\"      1952.0    2008.0           56.0  \n",
      "3           collector:\"Latz, P.\"      1875.0    2019.0          144.0  \n",
      "4      collector:\"Streimann, H.\"      1896.0    2001.0          105.0  \n"
     ]
    }
   ],
   "source": [
    "avh = pd.read_csv('data/avh_collectors.csv')\n",
    "avh = avh.iloc[:, 1:]\n",
    "\n",
    "print(avh.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the text search\n",
    "\n",
    "See https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536\n",
    "\n",
    "The ngrams function is used as an analyzer in the text search later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.7/site-packages (5.7)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from ftfy) (0.1.8)\n",
      "[' Kl', 'Kla', 'laz', 'aze', 'zen', 'eng', 'nga', 'ga ', 'a N', ' N ']\n",
      "[' Be', 'Bea', 'eau', 'aug', 'ugl', 'gle', 'leh', 'eho', 'hol', 'ole', 'le ', 'e A', ' Ac', 'Ac ']\n",
      "[' Wa', 'Wal', 'alr', 'lra', 'rae', 'aev', 'eve', 'ven', 'ens', 'ns ', 's O', ' Oh', 'Oh ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "!pip install ftfy # amazing text cleaning for decode issues..\n",
    "from ftfy import fix_text\n",
    "\n",
    "def ngrams(string, n=3):\n",
    "    string = fix_text(string) # fix text\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower()\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "\n",
    "print(ngrams('Klazenga, N.'))\n",
    "print(ngrams(avh.loc[0, 'label']))\n",
    "print(ngrams(wd_test.loc[0, 'canonical_string'].values[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize Wikidata names..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing data. This may take a while...\n",
      "Vectorizing completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "wikidata_names = wd_test['canonical_string']\n",
    "\n",
    "# vectorize wikidata names\n",
    "print('Vectorizing data. This may take a while...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(wikidata_names)\n",
    "print('Vectorizing completed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the function that performs the nearest neighbour matches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf) # tfidf contains the vectorized wikidata names from the previous step\n",
    "\n",
    "# matching query\n",
    "def getNearestN(query):\n",
    "  queryTFIDF_ = vectorizer.transform(query)\n",
    "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "  return distances, indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the matching\n",
    "\n",
    "Perform the NN matches on the AVH collector names and create a data frame with matches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting nearest neighbours...\n",
      "Completed in: 1.8628828525543213 s\n",
      "Finding matches...\n",
      "Building data frame...\n",
      "Done\n",
      "   index                     name      matched_name  distance\n",
      "0      0  Cooper, W. | Cooper, W.        Cooper, W.       0.0\n",
      "1    393            Wallace, B.J.     Wallace, B.J.       0.0\n",
      "2    392                Ashby, E.         Ashby, E.       0.0\n",
      "3    391               Hunter, J.        Hunter, J.       0.0\n",
      "4    390         Waterhouse, J.T.  Waterhouse, J.T.       0.0\n"
     ]
    }
   ],
   "source": [
    "avh_names = set(avh['label'].values) # convert list to set for better performance\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "print('Getting nearest neighbours...')\n",
    "distances, indices = getNearestN(avh_names)\n",
    "duration = time.time() - start\n",
    "print('Completed in:', duration, 's')\n",
    "\n",
    "avh_names = list(avh_names) # convert back to list\n",
    "\n",
    "print('Finding matches...')\n",
    "matches = []\n",
    "for i,j in enumerate(indices):\n",
    "  temp = [avh_names[i], wd_test.values[j][0][0], round(distances[i][0],2)]\n",
    "  matches.append(temp)\n",
    "\n",
    "print('Building data frame...')  \n",
    "matches = pd.DataFrame(matches, columns=['name','matched_name','distance'])\n",
    "print('Done') \n",
    "\n",
    "matches = matches.sort_values(['distance'])\n",
    "matches = matches.reset_index()\n",
    "\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output\n",
    "\n",
    "Link the matches data frame back to the AVH collectors and Wikidata items data frames..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>i18nCode</th>\n",
       "      <th>count</th>\n",
       "      <th>fq</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>activity_span</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>matched_name</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauglehole, A.C.</td>\n",
       "      <td>collector.Beauglehole, A.C.</td>\n",
       "      <td>90942</td>\n",
       "      <td>collector:\"Beauglehole, A.C.\"</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>184</td>\n",
       "      <td>Beauglehole, A.C.</td>\n",
       "      <td>Beaglehole, E.</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forster, P.I.</td>\n",
       "      <td>collector.Forster, P.I.</td>\n",
       "      <td>64649</td>\n",
       "      <td>collector:\"Forster, P.I.\"</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>41</td>\n",
       "      <td>Forster, P.I.</td>\n",
       "      <td>Forster, P.I.</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyland, B.</td>\n",
       "      <td>collector.Hyland, B.</td>\n",
       "      <td>57265</td>\n",
       "      <td>collector:\"Hyland, B.\"</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43</td>\n",
       "      <td>Hyland, B.</td>\n",
       "      <td>Hyland, B.</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latz, P.</td>\n",
       "      <td>collector.Latz, P.</td>\n",
       "      <td>51230</td>\n",
       "      <td>collector:\"Latz, P.\"</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>609</td>\n",
       "      <td>Latz, P.</td>\n",
       "      <td>Latz, P.K.</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Streimann, H.</td>\n",
       "      <td>collector.Streimann, H.</td>\n",
       "      <td>45346</td>\n",
       "      <td>collector:\"Streimann, H.\"</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>123</td>\n",
       "      <td>Streimann, H.</td>\n",
       "      <td>Streimann, H.</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                     i18nCode  count  \\\n",
       "0  Beauglehole, A.C.  collector.Beauglehole, A.C.  90942   \n",
       "1      Forster, P.I.      collector.Forster, P.I.  64649   \n",
       "2         Hyland, B.         collector.Hyland, B.  57265   \n",
       "3           Latz, P.           collector.Latz, P.  51230   \n",
       "4      Streimann, H.      collector.Streimann, H.  45346   \n",
       "\n",
       "                              fq  start_date  end_date  activity_span  index  \\\n",
       "0  collector:\"Beauglehole, A.C.\"      1865.0    2005.0          140.0    184   \n",
       "1      collector:\"Forster, P.I.\"      1955.0    2018.0           63.0     41   \n",
       "2         collector:\"Hyland, B.\"      1952.0    2008.0           56.0     43   \n",
       "3           collector:\"Latz, P.\"      1875.0    2019.0          144.0    609   \n",
       "4      collector:\"Streimann, H.\"      1896.0    2001.0          105.0    123   \n",
       "\n",
       "                name    matched_name  distance  \n",
       "0  Beauglehole, A.C.  Beaglehole, E.      0.86  \n",
       "1      Forster, P.I.   Forster, P.I.      0.00  \n",
       "2         Hyland, B.      Hyland, B.      0.00  \n",
       "3           Latz, P.      Latz, P.K.      0.69  \n",
       "4      Streimann, H.   Streimann, H.      0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join matches data frame back to avh dataframe \n",
    "avh_matches = pd.merge(avh, matches, left_on='label', right_on='name')\n",
    "\n",
    "avh_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With grouped Wikidata items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating items aggregate...\n",
      "Done.\n",
      "Creating item labels aggregate...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>activity_span</th>\n",
       "      <th>name</th>\n",
       "      <th>matched_name</th>\n",
       "      <th>distance</th>\n",
       "      <th>item_count</th>\n",
       "      <th>items</th>\n",
       "      <th>item_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Hamilton, A.G.</td>\n",
       "      <td>692</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Hamilton, A.G.</td>\n",
       "      <td>Hamilton, A.G.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q21514592</td>\n",
       "      <td>Alexandra Greenlaw Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Bayer, R.J.</td>\n",
       "      <td>693</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Bayer, R.J.</td>\n",
       "      <td>Bayer, R.J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q7291564</td>\n",
       "      <td>Randall James Bayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Catcheside, D.G.</td>\n",
       "      <td>693</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Catcheside, D.G.</td>\n",
       "      <td>Catcheside, D.G.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q21165808</td>\n",
       "      <td>David Guthrie Catcheside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Wright, G.T.</td>\n",
       "      <td>694</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Wright, G.T.</td>\n",
       "      <td>Wright, G.T.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q59606231</td>\n",
       "      <td>Genevieve T. Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Scarlett, N.</td>\n",
       "      <td>697</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Scarlett, N.</td>\n",
       "      <td>Scarlett, N.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q19004122</td>\n",
       "      <td>N.H. Scarlett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                label  count  start_date  end_date  activity_span  \\\n",
       "992    Hamilton, A.G.    692      1882.0    1992.0          110.0   \n",
       "990       Bayer, R.J.    693      1944.0    2009.0           65.0   \n",
       "991  Catcheside, D.G.    693      1951.0    1991.0           40.0   \n",
       "989      Wright, G.T.    694      1998.0    2019.0           21.0   \n",
       "674      Scarlett, N.    697      1947.0    1998.0           51.0   \n",
       "\n",
       "                 name      matched_name  distance  item_count  \\\n",
       "992    Hamilton, A.G.    Hamilton, A.G.       0.0           1   \n",
       "990       Bayer, R.J.       Bayer, R.J.       0.0           1   \n",
       "991  Catcheside, D.G.  Catcheside, D.G.       0.0           1   \n",
       "989      Wright, G.T.      Wright, G.T.       0.0           1   \n",
       "674      Scarlett, N.      Scarlett, N.       0.0           1   \n",
       "\n",
       "                                        items                  item_labels  \n",
       "992  http://www.wikidata.org/entity/Q21514592  Alexandra Greenlaw Hamilton  \n",
       "990   http://www.wikidata.org/entity/Q7291564          Randall James Bayer  \n",
       "991  http://www.wikidata.org/entity/Q21165808     David Guthrie Catcheside  \n",
       "989  http://www.wikidata.org/entity/Q59606231          Genevieve T. Wright  \n",
       "674  http://www.wikidata.org/entity/Q19004122                N.H. Scarlett  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# link counts of wikidata items with canonical name string\n",
    "avh_matches_g1 = pd.merge(avh_matches, wd_test, left_on='matched_name', right_on='canonical_string')\n",
    "avh_matches_g1.rename(columns = {list(avh_matches_g1)[-1]: 'item_count'}, inplace=True)\n",
    "\n",
    "# link wikidata items with canonical name string (pipe separated if more than one)\n",
    "print('Creating items aggregate...')\n",
    "wikidata_uniq_items = wikidata.groupby(['canonical_string'])['item'].apply('|'.join).reset_index()\n",
    "print('Done.')\n",
    "avh_matches_g2 = pd.merge(avh_matches_g1, wikidata_uniq_items, left_on='matched_name', right_on='canonical_string')\n",
    "avh_matches_g2.rename(columns = {list(avh_matches_g2)[-1]: 'items'}, inplace=True)\n",
    "\n",
    "# link wikidata items with canonical name string (pipe separated if more than one)\n",
    "print('Creating item labels aggregate...')\n",
    "wikidata_uniq_itemlabels = wikidata.groupby(['canonical_string'])['itemLabel'].apply('|'.join).reset_index()\n",
    "print('Done.')\n",
    "avh_matches_g3 = pd.merge(avh_matches_g2, wikidata_uniq_itemlabels, left_on='matched_name', right_on='canonical_string')\n",
    "avh_matches_g3.rename(columns = {list(avh_matches_g3)[-1]: 'item_labels'}, inplace=True)\n",
    "\n",
    "# Remove superfluous columns\n",
    "avh_matches_group = avh_matches_g3[['label', 'count', 'start_date', 'end_date', 'activity_span', \n",
    "                                   'name', 'matched_name', 'distance', 'item_count', \n",
    "                                   'items', 'item_labels']]\n",
    "avh_matches_group.sort_values(by=['distance', 'item_count', 'count'], inplace=True)\n",
    "\n",
    "avh_matches_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "avh_matches_group.to_csv('data/avhcoll_wikidata_matches_group.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CSV file with match results](./data/avhcoll_wikidata_matches_group.csv) (This downloads the file to your computer.)\n",
    "\n",
    "With individual Wikidata items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>activity_span</th>\n",
       "      <th>name</th>\n",
       "      <th>matched_name</th>\n",
       "      <th>distance</th>\n",
       "      <th>dup_count</th>\n",
       "      <th>item</th>\n",
       "      <th>...</th>\n",
       "      <th>orcid</th>\n",
       "      <th>viaf</th>\n",
       "      <th>isni</th>\n",
       "      <th>harv</th>\n",
       "      <th>ipni</th>\n",
       "      <th>abbr</th>\n",
       "      <th>yob</th>\n",
       "      <th>yod</th>\n",
       "      <th>wyb</th>\n",
       "      <th>wye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forster, P.I.</td>\n",
       "      <td>64649</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Forster, P.I.</td>\n",
       "      <td>Forster, P.I.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q9057027</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18907-1</td>\n",
       "      <td>P.I.Forst.</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hyland, B.</td>\n",
       "      <td>57265</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Hyland, B.</td>\n",
       "      <td>Hyland, B.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q4893242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4262-1</td>\n",
       "      <td>B.Hyland</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Streimann, H.</td>\n",
       "      <td>45346</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Streimann, H.</td>\n",
       "      <td>Streimann, H.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q21339679</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69178760</td>\n",
       "      <td>0000 0001 1573 7118</td>\n",
       "      <td>2053</td>\n",
       "      <td>15669-1</td>\n",
       "      <td>Streimann</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elix, J.A.</td>\n",
       "      <td>39702</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>Elix, J.A.</td>\n",
       "      <td>Elix, J.A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q21339171</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5178780</td>\n",
       "      <td>0000 0000 8084 828X</td>\n",
       "      <td>93027</td>\n",
       "      <td>18445-1</td>\n",
       "      <td>Elix</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blake, S.T.</td>\n",
       "      <td>33031</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Blake, S.T.</td>\n",
       "      <td>Blake, S.T.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q2984580</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304022808</td>\n",
       "      <td>0000 0000 6521 9151</td>\n",
       "      <td>13863</td>\n",
       "      <td>838-1</td>\n",
       "      <td>S.T.Blake</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  count  start_date  end_date  activity_span           name  \\\n",
       "0  Forster, P.I.  64649      1955.0    2018.0           63.0  Forster, P.I.   \n",
       "1     Hyland, B.  57265      1952.0    2008.0           56.0     Hyland, B.   \n",
       "2  Streimann, H.  45346      1896.0    2001.0          105.0  Streimann, H.   \n",
       "3     Elix, J.A.  39702      1878.0    2020.0          142.0     Elix, J.A.   \n",
       "4    Blake, S.T.  33031      1846.0    1996.0          150.0    Blake, S.T.   \n",
       "\n",
       "    matched_name  distance  dup_count  \\\n",
       "0  Forster, P.I.       0.0          1   \n",
       "1     Hyland, B.       0.0          1   \n",
       "2  Streimann, H.       0.0          1   \n",
       "3     Elix, J.A.       0.0          1   \n",
       "4    Blake, S.T.       0.0          1   \n",
       "\n",
       "                                       item  ... orcid       viaf  \\\n",
       "0   http://www.wikidata.org/entity/Q9057027  ...   NaN        NaN   \n",
       "1   http://www.wikidata.org/entity/Q4893242  ...   NaN        NaN   \n",
       "2  http://www.wikidata.org/entity/Q21339679  ...   NaN   69178760   \n",
       "3  http://www.wikidata.org/entity/Q21339171  ...   NaN    5178780   \n",
       "4   http://www.wikidata.org/entity/Q2984580  ...   NaN  304022808   \n",
       "\n",
       "                  isni   harv     ipni        abbr     yob     yod wyb wye  \n",
       "0                  NaN    NaN  18907-1  P.I.Forst.  1961.0     NaN NaN NaN  \n",
       "1                  NaN    NaN   4262-1    B.Hyland  1937.0     NaN NaN NaN  \n",
       "2  0000 0001 1573 7118   2053  15669-1   Streimann  1938.0  2001.0 NaN NaN  \n",
       "3  0000 0000 8084 828X  93027  18445-1        Elix  1941.0     NaN NaN NaN  \n",
       "4  0000 0000 6521 9151  13863    838-1   S.T.Blake  1910.0  1973.0 NaN NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join wikidata items to avh collectors matches\n",
    "avh_matches_t1 = pd.merge(avh_matches, wikidata, left_on='matched_name', right_on='canonical_string')\n",
    "# avh_matches_t1.drop(columns=['canonical_string'])\n",
    "\n",
    "# link counts of wikidata items with same canonical name string\n",
    "avh_matches_t2 = pd.merge(avh_matches_t1, wd_test, left_on=\"matched_name\", right_on=\"canonical_string\")\n",
    "avh_matches_t2.rename(columns = {list(avh_matches_t2)[-1]: 'dup_count'}, inplace=True)\n",
    "\n",
    "# Clean up data frame by removing duplicated columns\n",
    "# # print(list(avh_matches_t2.columns))\n",
    "cols = ['label', 'count', 'start_date', 'end_date', 'activity_span', \n",
    "        'name', 'matched_name', 'distance', 'dup_count', \n",
    "        'item', 'itemLabel', 'surname', 'initials', 'canonical_string', \n",
    "        'orcid', 'viaf', 'isni', 'harv', 'ipni', 'abbr', \n",
    "        'yob', 'yod', 'wyb', 'wye']\n",
    "avh_matches_indiv = avh_matches_t2[cols]\n",
    "\n",
    "# Order rows by NN distance and dup. count\n",
    "avh_matches_indiv.sort_values(['distance', 'dup_count', 'count'], ascending=[True, True, False], inplace=True)\n",
    "avh_matches_indiv.reset_index(inplace=True)\n",
    "\n",
    "avh_matches_indiv = avh_matches_indiv.iloc[:,1:]\n",
    "\n",
    "avh_matches_indiv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "avh_matches_indiv.to_csv('data/avhcoll_wikidata_matches_indiv.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CSV file with match results](./data/avhcoll_wikidata_matches_indiv.csv) (This downloads the file to your computer.)\n",
    "\n",
    "Explanation of columns:\n",
    "\n",
    "Column | Description\n",
    "-|-\n",
    "**AVH collectors** |\n",
    "label | Collector name string from AVH\n",
    "count | Number of records with this collector name string in AVH\n",
    "start_date | Year of first collection\n",
    "end_date | Year of last collection\n",
    "activity_span | Number of years between first and last collection\n",
    "**Name matching** |\n",
    "name | input name; = AVH collector name string\n",
    "matched_name | matched name; = Wikidata item label name is matched to\n",
    "distance | Nearest Neighbour distance between the name and matched name; the lower the value, the better the match\n",
    "**Wikidata**\n",
    "item | Wikidata Item ID (URL)\n",
    "itemLabel | Wikidata Item label\n",
    "surname\t| Surname; derived from item label\n",
    "initials | Initials; derived from item label\n",
    "canonical_string | Canonical name string; derived from item label, used for matching\n",
    "orcid | ORCID ([P496](https://www.wikidata.org/wiki/Property:P496))\n",
    "viaf | VIAF ID ([P214](https://www.wikidata.org/wiki/Property:P214))\n",
    "isni | ISNI ID ([P213](https://www.wikidata.org/wiki/Property:P496))\t\n",
    "harv | Harvard Index of Botanists ID ([P6264](https://www.wikidata.org/wiki/Property:P6264))\n",
    "ipni | IPNI author ID ([P586](https://www.wikidata.org/wiki/Property:P586))\n",
    "abbr | botanist author abbreviation (standard form) ([P428](https://www.wikidata.org/wiki/Property:P428))\n",
    "yob\t| Year of birth (derived from [P569](https://www.wikidata.org/wiki/Property:P569))\n",
    "yod\t| Year of death (derived from [P496](https://www.wikidata.org/wiki/Property:P570))\n",
    "wyb\t| Start year of work period ([P2031](https://www.wikidata.org/wiki/Property:P2031))\n",
    "wye | End year of work period ([P2032](https://www.wikidata.org/wiki/Property:P2032))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
